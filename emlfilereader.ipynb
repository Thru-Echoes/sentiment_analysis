{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a328dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/erindominguez/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/erindominguez/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bs4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bs4) (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4->bs4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4->bs4) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "%pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "%pip install --upgrade pip\n",
    "\n",
    "%pip install requests\n",
    "import requests\n",
    "\n",
    "%pip install bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "740b6d30",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'eml_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#setting working directory to eml_files\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meml_files\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'eml_files'"
     ]
    }
   ],
   "source": [
    "#setting working directory to eml_files\n",
    "os.chdir('eml_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82885060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.elsalvador.com/noticias/nacional/mercados-mercado-cuscatlan-alcaldia-de-san-salvador-centro-/1209302/2025/',\n",
       " 'https://www.elsalvador.com/opinion/editoriales/mineria-/1209390/2025/',\n",
       " 'https://www.laprensagrafica.com/tendencias/Un-Pikachu-revolucionario-un-manifestante-disfrazado-de-Pokemon-se-unio-a-las-protestas-en-Turquia-20250329-0020.html',\n",
       " 'https://www.laprensagrafica.com/opinion/Las-locuras-del-emperador-II-20250328-0081.html',\n",
       " 'https://www.revistafactum.com/slm-grok/',\n",
       " 'https://diario.elmundo.sv/el-mundo/un-pueblo-del-sur-de-honduras-podria-perder-su-historica-iglesia-por-la-explotacion-minera',\n",
       " 'https://diario.elmundo.sv/nacionales/organizaciones-dicen-que-el-sistema-judicial-esta-a-prueba-tras-la-entrega-de-mas-de-59000-firmas-contra-de-la-mineria']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def urls_in_file(file_name):\n",
    "    \"\"\" Takes an .eml file name as a string and returns a list of all unique urls linking to news sources \"\"\"\n",
    "\n",
    "    #creates file path by joining the current working directory with the file name\n",
    "    file_path = os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "    #reads the file and removes newlines and equal signs (which are placed at the end of each line)\n",
    "    with open(file_path, 'r') as file:\n",
    "        textfile = file.read().replace('\\n', '').replace('=', '')\n",
    "    \n",
    "    #any strings without white spaces starting with 3Dhttps:// and ending with &amp, non-greedy matching\n",
    "    valid_urls = re.findall('3D(https://\\S*?)?&amp', textfile)\n",
    "    \n",
    "    #creates a list of each unique url (removes duplicates)\n",
    "    unique_urls = list(set(valid_urls))\n",
    "    \n",
    "    return unique_urls\n",
    "\n",
    "#demonstrates the function with the first file in the folder\n",
    "urls_in_file('1. El Salvador Mineria 1-94 eml/Google Alert - El Salvador minería_1.eml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def urls_in_folder(folder_name):\n",
    "    \"\"\" Takes a folder of .eml files as a string and returns a list of all unique urls contained in each of the \n",
    "    files in the folder \n",
    "\"\"\"\n",
    "    \n",
    "    #creates a list of all file names in folder_name\n",
    "    filenames = os.listdir(folder_name)\n",
    "    filenames = [os.path.join(folder_name, file) for file in filenames]\n",
    "    \n",
    "    #creates a list to store the unique urls found in each file using urls_in_file function\n",
    "    all_urls = []\n",
    "    for file in filenames:\n",
    "        urls = urls_in_file(file)\n",
    "        all_urls.extend(urls)\n",
    "    \n",
    "    return all_urls\n",
    "\n",
    "#demonstrates the function with folder '1. El Salvador Mineria 1-94 eml'\n",
    "urls_in_folder('1. El Salvador Mineria 1-94 eml')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ab3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_website_text(url):\n",
    "    \"\"\"Takes in a url as a string and returns the text content of the webpage, including headers, footers, and paragraphs.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        extracted_text = soup.get_text(separator='\\n', strip=True)\n",
    "        return extracted_text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "    \n",
    "def clean_extracted_text(text, section='body', cutoff=20):\n",
    "    \"\"\"Cleans the text extracted using extract_website_text and removes short paragraphs (headers, footers, etc...) based on word count cutoff\"\"\"\n",
    "    if text is None:\n",
    "        return None\n",
    "    elif section == 'body':\n",
    "        split = text.split('\\n') #split the text into a list divided every time there is a new line \\n\n",
    "        body = [paragraph for paragraph in split if len(paragraph.split()) > cutoff] #remove paragraphs with less than CUTOFF words.\n",
    "        body_text = ' '.join(body) #combine remaining text into a single string\n",
    "        print(body_text)\n",
    "    elif section == 'header':\n",
    "        # Assuming the header is the first part of the text before the first paragraph\n",
    "        header = text.split('\\n')[0] if '\\n' in text else text.split('-')[0]\n",
    "        return header.strip()\n",
    "\n",
    "\n",
    "example_text = extract_website_text('https://www.contrapunto.com.sv/muro-colapso-tras-sismo-en-san-salvador-y-dejo-a-una-persona-herida/')\n",
    "clean_extracted_text(example_text, section='body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec74c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_emls_in_folder(folder_name):\n",
    "    \"\"\"Extracts text from all .eml files in a folder and returns a table filled with urls, article titles, and body text.\"\"\"\n",
    "    \n",
    "    urls = urls_in_folder(folder_name)\n",
    "    \n",
    "    raw_url_text = [extract_website_text(url) for url in urls]\n",
    "    cleaned_text = [clean_extracted_text(text, section='body') for text in raw_url_text]\n",
    "    extracted_info = pd.DataFrame({\n",
    "        'url': urls_in_folder,\n",
    "        'title': [clean_extracted_text(text, section='header') for text in raw_url_text],\n",
    "        'body': cleaned_text\n",
    "    })\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "#mineria_1 = extract_info_from_emls_in_folder('1. El Salvador Mineria 1-94 eml')\n",
    "#mineria_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3c78e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '1. El Salvador Mineria 1-94 eml/Google Alert - El Salvador minería_1.eml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m     extracted_info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m: urls_in_folder,\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: [clean_extracted_text(text, section\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m raw_url_text],\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m: cleaned_text\n\u001b[1;32m     13\u001b[0m     })\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extracted_info\n\u001b[0;32m---> 17\u001b[0m mineria_2 \u001b[38;5;241m=\u001b[39m \u001b[43memls_in_file_to_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1. El Salvador Mineria 1-94 eml/Google Alert - El Salvador minería_1.eml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m mineria_2\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36memls_in_file_to_table\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extracts text from the file_name in a folder and returns a table filled with urls, article titles, and body text.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#file_path = os.path.join('1. El Salvador Mineria 1-94 eml', file_name)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m urls \u001b[38;5;241m=\u001b[39m \u001b[43murls_in_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m raw_url_text \u001b[38;5;241m=\u001b[39m [extract_website_text(url) \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls]\n\u001b[1;32m      8\u001b[0m cleaned_text \u001b[38;5;241m=\u001b[39m [clean_extracted_text(text, section\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m raw_url_text]\n",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m, in \u001b[0;36murls_in_folder\u001b[0;34m(folder_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Takes a folder of .eml files as a string and returns a list of all unique urls contained in each of the \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    files in the folder \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#creates a list of all file names in folder_name\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     filenames \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(folder_name)\n\u001b[1;32m      8\u001b[0m     filenames \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_name, file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m filenames]\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#creates a list to store the unique urls found in each file using urls_in_file function\u001b[39;00m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '1. El Salvador Mineria 1-94 eml/Google Alert - El Salvador minería_1.eml'"
     ]
    }
   ],
   "source": [
    "def emls_in_file_to_table(file_name):\n",
    "    \"\"\"Extracts text from the file_name in a folder and returns a table filled with urls, article titles, and body text.\"\"\"\n",
    "    \n",
    "    urls = urls_in_folder(file_name)\n",
    "    \n",
    "    raw_url_text = [extract_website_text(url) for url in urls]\n",
    "    cleaned_text = [clean_extracted_text(text, section='body') for text in raw_url_text]\n",
    "    extracted_info = pd.DataFrame({\n",
    "        'url': urls_in_folder,\n",
    "        'title': [clean_extracted_text(text, section='header') for text in raw_url_text],\n",
    "        'body': cleaned_text\n",
    "    })\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "mineria_2 = emls_in_file_to_table('Google Alert - El Salvador minería_1.eml')\n",
    "mineria_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749a6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
