{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a328dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/erindominguez/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "#%pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "#%pip install --upgrade pip\n",
    "\n",
    "#%pip install requests\n",
    "import requests\n",
    "\n",
    "#%pip install bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#this is how I imported the library i've been using to extract keywords\n",
    "#I have not been able to get it to work yet (see extract_keywords_from_text function)\n",
    "#if anyone has suggestions or other libraries that might work better, please let me know!\n",
    "\n",
    "#this was copied from https://stackoverflow.com/questions/38916452/nltk-download-ssl-certificate-verify-failed\n",
    "#correcting an error that sometimes occurs when downloading nltk functions\n",
    "\n",
    "#%pip install rake-nltk\n",
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82885060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def urls_in_file(file_name):\n",
    "    \"\"\" Takes an .eml file name as a string and returns a list of all unique urls linking to news sources \"\"\"\n",
    "\n",
    "    #reads the file and removes newlines and equal signs (which are placed at the end of each line)\n",
    "    with open(file_name, 'r') as file:\n",
    "        textfile = file.read().replace('\\n', '').replace('=', '')\n",
    "    \n",
    "    #any strings without white spaces starting with 3Dhttps:// and ending with &amp, non-greedy matching\n",
    "    valid_urls = re.findall('3D(https://\\S*?)?&amp', textfile)\n",
    "    \n",
    "    #creates a list of each unique url (removes duplicates)\n",
    "    unique_urls = list(set(valid_urls))\n",
    "    \n",
    "    return unique_urls\n",
    "\n",
    "#demonstrates the function with the first file in the folder\n",
    "#urls_in_file('eml_files/1. El Salvador Mineria 1-94 eml/Google Alert - El Salvador minería_1.eml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce63e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def urls_in_folder(folder_name):\n",
    "    \"\"\" Takes a folder of .eml files as a string and returns a list of all unique urls contained in each of the \n",
    "    files in the folder \n",
    "\"\"\"\n",
    "    \n",
    "    #creates a list of all file names in folder_name\n",
    "    filenames = os.listdir(folder_name)\n",
    "    filenames = [os.path.join(folder_name, file) for file in filenames]\n",
    "    \n",
    "    #creates a list to store the unique urls found in each file using urls_in_file function\n",
    "    all_urls = []\n",
    "    for file in filenames:\n",
    "        urls = urls_in_file(file)\n",
    "        all_urls.extend(urls)\n",
    "    \n",
    "    return all_urls\n",
    "\n",
    "#demonstrates the function with folder '1. El Salvador Mineria 1-94 eml'\n",
    "#urls_in_folder('eml_files/1. El Salvador Mineria 1-94 eml')[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e385944d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bitcoin', 'El Salvador']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_keywords_from_eml(file_name):\n",
    "    \"\"\" \n",
    "    Takes an .eml file name as a string and returns a list of the keywords used in the Google Alerts\n",
    "    that generated the file. \n",
    "\n",
    "    Only works with Google Alert .eml files with an ENGLISH subject line, which are formatted as:\n",
    "    Subject: Google Alert - \"keyword1\" \"keyword2\" \"keyword3\"\n",
    "\n",
    "    Google Alerts in Spanish appear to be formatted with UTF-8 encoding, which results in subject lines like:\n",
    "    Subject: =?UTF-8?Q?Google_Alert_=2D_El_Salvador_miner=C3=ADa?=\n",
    "\n",
    "    NOTE: I chose to use the actual eml file text rather than the name of the file because I didn't want\n",
    "    the function to be dependent on the file name format, which might vary in the future.\n",
    "    \"\"\"   \n",
    "    \n",
    "    #reads the file and removes equal signs (which are placed at the end of each line)\n",
    "    with open(file_name, 'r') as file:\n",
    "        textfile = file.read().replace('=', '')\n",
    "    \n",
    "    #creates a list of keywords found in the textfile\n",
    "    pattern = 'Subject: Google Alert - (.*)' \n",
    "    keyword_block = re.findall(pattern, textfile)\n",
    "    keywords = keyword_block[0].split('\" \"')\n",
    "    keywords = [keywords[i].replace('\"', '').replace(\"'\", \"\") for i in range(len(keywords))]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "#demonstrates function with Google Alert - Bitcoin_ _El Salvador__1.eml\n",
    "extract_keywords_from_eml('eml_files/Google Alert - _Bitcoin_ _El Salvador__1.eml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877ab3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Muro colapsó tras sismo en San Salvador y dejó a una persona herida',\n",
       " 'Date not found',\n",
       " 'Una persona quedó atrapada tras el colapso de un muro en San Salvador, provocado por un sismo. Fue rescatada y atendida por Cruz Verde Salvadoreña. Una persona quedó atrapada bajo los escombros de un muro que colapsó en la colonia Las Flores, calle Agua Caliente, San Salvador Este, tras el sismo registrado la tarde del lunes 5 de enero a las 5:37 p. m.; La víctima, cuya identidad no ha sido revelada, fue localizada por un residente del lugar y posteriormente rescatada por elementos de Cruz Verde Salvadoreña, quienes le brindaron primeros auxilios antes de trasladarla a un centro asistencial. Este sismo fue una de las réplicas del movimiento telúrico de magnitud 6.3 que ocurrió frente a la costa de La Paz a las 11:18 a.m. del domingo 5 de enero. Según el Ministerio de Medio Ambiente, desde entonces se han registrado 147 réplicas, de las cuales 21 han sido sentidas por la población. Las autoridades explicaron que esta actividad sísmica es producto del proceso de subducción entre las placas de Cocos y Caribe. No se reporta amenaza de tsunami para las costas salvadoreñas.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_website_details(url, cutoff=20):\n",
    "    \"\"\"\n",
    "    Takes in a url as a string and returns the text content of the webpage, removing paragraphs shorter than cutoff words.\n",
    "    Returns a list containing the title, date, and body text of the webpage.\n",
    "    If the webpage cannot be accessed, returns a list of None values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser') #creates a BeautifulSoup object from the webpage content\n",
    "\n",
    "        #Extracts text from webpage and attempts to remove headers and footers\n",
    "        extracted_text = soup.get_text(separator='\\n', strip=True)\n",
    "        split = extracted_text.split('\\n') #split the text into a list divided every time there is a new line \\n\n",
    "        body = [paragraph for paragraph in split if len(paragraph.split()) > cutoff] #remove paragraphs with less than CUTOFF words\n",
    "        body_text = ' '.join(body) #combine remaining text into a single string\n",
    "\n",
    "        #Extracts title from webpage\n",
    "        title = soup.title.string if soup.title else 'Title not found'\n",
    "\n",
    "        #Extracts date from webpage, if available\n",
    "        #This part of the function isn't working yet, so it always returns 'Date not found'\n",
    "        date = soup.find(\"span\", class_=\"post-date\").get_text(strip=True) if soup.find(\"span\", class_=\"post-date\") else 'Date not found'\n",
    "        \n",
    "        #Creating a BeautifulSoup object takes significant time, so this function extracts all neccessary information in one go\n",
    "        #which is more efficient than creating separate functions for title, date, and body text.\n",
    "\n",
    "        #Returns a list containing the title, date, and body text\n",
    "        return [title, date, body_text]\n",
    "    \n",
    "    # If the webpage cannot be accessed, return a list of None values to fill in the table\n",
    "    # It may be helpful to later fill in the error values instead of None to troubleshoot different problems\n",
    "    except requests.RequestException as e:\n",
    "        # Uncomment the next line to print errors during debugging\n",
    "        #print(f\"Error fetching {url}: {e}\")\n",
    "        return [None, None, None]\n",
    "    \n",
    "\n",
    "#this used to be a separate function, but it is now integrated into extract_website_details\n",
    "#def clean_extracted_text(text, cutoff=20):\n",
    "    #\"\"\"Cleans the text extracted using extract_website_text and removes short paragraphs (headers, footers, etc...) based on word count cutoff\"\"\"\n",
    "    #if text is None or text == [None, None, None]:\n",
    "    #    return [None, None, None]\n",
    "    #else: \n",
    "    #    split = text[2].split('\\n') #split the text into a list divided every time there is a new line \\n\n",
    "    #    body = [paragraph for paragraph in split if len(paragraph.split()) > cutoff] #remove paragraphs with less than CUTOFF words.\n",
    "    #    body_text = ' '.join(body) #combine remaining text into a single string\n",
    "    #    return [text[0], text[1], body_text]\n",
    "\n",
    "#demonstrates the extract_website_details function with an example url\n",
    "example_text = extract_website_details('https://www.contrapunto.com.sv/muro-colapso-tras-sismo-en-san-salvador-y-dejo-a-una-persona-herida/')\n",
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec3c78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://blockchain.news/flashnews/trump-to-mee...</td>\n",
       "      <td>Trump to Meet El Salvador Leader at White Hous...</td>\n",
       "      <td>Date not found</td>\n",
       "      <td>According to @rovercrc, former President Trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://tradersunion.com/news/editors-picks/sh...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://cointelegraph.com/learn/articles/bitco...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.novinite.com/articles/231545/The%2...</td>\n",
       "      <td>The Role of Cryptocurrency in Developing Econo...</td>\n",
       "      <td>Date not found</td>\n",
       "      <td>Money, for most people, is something they don’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.crypto-reporter.com/press-releases...</td>\n",
       "      <td>Bukele Rejects IMF, Keeps Buying BTC, and FXGu...</td>\n",
       "      <td>Date not found</td>\n",
       "      <td>El Salvador’s President Nayib Bukele made news...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://crypto.news/trump-plans-white-house-vi...</td>\n",
       "      <td>Trump plans White House visit for El Salvador’...</td>\n",
       "      <td>Date not found</td>\n",
       "      <td>by Bloomberg, follows Bukele’s agreement to de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://news.bitcoin.com/first-tokenized-wareh...</td>\n",
       "      <td>First Tokenized Warehouse Complex Built in El ...</td>\n",
       "      <td>Date not found</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://cryptobriefing.com/bitcoin-meeting-whi...</td>\n",
       "      <td>Trump plans to meet with Bitcoin bull Nayib Bu...</td>\n",
       "      <td>Date not found</td>\n",
       "      <td>The two pro-Bitcoin leaders have maintained co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://coincentral.com/trump-to-host-nayib-bu...</td>\n",
       "      <td>Trump to Host Nayib Bukele Following Deportati...</td>\n",
       "      <td>Date not found</td>\n",
       "      <td>Trump plans to host El Salvador's President Bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.cryptoninjas.net/news/new-legislat...</td>\n",
       "      <td>New Legislation Introduced in Panama to Turn t...</td>\n",
       "      <td>Date not found</td>\n",
       "      <td>Panama is set to introduce a comprehensive dra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://blockchain.news/flashnews/trump-to-mee...   \n",
       "1  https://tradersunion.com/news/editors-picks/sh...   \n",
       "2  https://cointelegraph.com/learn/articles/bitco...   \n",
       "3  https://www.novinite.com/articles/231545/The%2...   \n",
       "4  https://www.crypto-reporter.com/press-releases...   \n",
       "5  https://crypto.news/trump-plans-white-house-vi...   \n",
       "6  https://news.bitcoin.com/first-tokenized-wareh...   \n",
       "7  https://cryptobriefing.com/bitcoin-meeting-whi...   \n",
       "8  https://coincentral.com/trump-to-host-nayib-bu...   \n",
       "9  https://www.cryptoninjas.net/news/new-legislat...   \n",
       "\n",
       "                                               title            date  \\\n",
       "0  Trump to Meet El Salvador Leader at White Hous...  Date not found   \n",
       "1                                               None            None   \n",
       "2                                               None            None   \n",
       "3  The Role of Cryptocurrency in Developing Econo...  Date not found   \n",
       "4  Bukele Rejects IMF, Keeps Buying BTC, and FXGu...  Date not found   \n",
       "5  Trump plans White House visit for El Salvador’...  Date not found   \n",
       "6  First Tokenized Warehouse Complex Built in El ...  Date not found   \n",
       "7  Trump plans to meet with Bitcoin bull Nayib Bu...  Date not found   \n",
       "8  Trump to Host Nayib Bukele Following Deportati...  Date not found   \n",
       "9  New Legislation Introduced in Panama to Turn t...  Date not found   \n",
       "\n",
       "                                                body  \n",
       "0  According to @rovercrc, former President Trump...  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3  Money, for most people, is something they don’...  \n",
       "4  El Salvador’s President Nayib Bukele made news...  \n",
       "5  by Bloomberg, follows Bukele’s agreement to de...  \n",
       "6                                                     \n",
       "7  The two pro-Bitcoin leaders have maintained co...  \n",
       "8  Trump plans to host El Salvador's President Bu...  \n",
       "9  Panama is set to introduce a comprehensive dra...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def urls_to_table(urls):\n",
    "    \"\"\"Extracts text list of urls returns a table filled with urls, article titles, and body text.\"\"\"\n",
    "    \n",
    "    url_title_date_text = [extract_website_details(url) for url in urls]\n",
    "\n",
    "    cleaned_texts = [text[2] for text in url_title_date_text]\n",
    "    dates = [text[1] for text in url_title_date_text]\n",
    "    titles = [text[0] for text in url_title_date_text]\n",
    "\n",
    "    #[clean_extracted_text(text, section='header') for text in raw_url_text]\n",
    "    #cleaned_texts = [clean_extracted_text(text, section='body') for text in raw_url_text]\n",
    "\n",
    "    extracted_info = pd.DataFrame({\n",
    "        'url': urls,\n",
    "        'title': titles,\n",
    "        'date': dates,\n",
    "        'body': cleaned_texts\n",
    "    })\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "#demonstrates the function with the first file in the folder\n",
    "urls_1 = urls_in_file('eml_files/Google Alert - _Bitcoin_ _El Salvador__1.eml')\n",
    "mineria_1 = urls_to_table(urls_1)\n",
    "mineria_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749a6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.elsalvador.com/opinion/editoriales...</td>\n",
       "      <td>Un equipo técnico–científico - Noticias de El ...</td>\n",
       "      <td>Date not found</td>\n",
       "      <td>El periodismo que hacemos requiere tiempo, esf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://lapagina.com.sv/deportes/ancelotti-se-...</td>\n",
       "      <td>Ancelotti se lleva a Arabia a cuatro canterano...</td>\n",
       "      <td>Date not found</td>\n",
       "      <td>Ancelotti se lleva a Arabia a cuatro canterano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://diario1.com/zona-deportiva/2025/01/el-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.elsalvador.com/opinion/editoriales...   \n",
       "1  https://lapagina.com.sv/deportes/ancelotti-se-...   \n",
       "2  https://diario1.com/zona-deportiva/2025/01/el-...   \n",
       "\n",
       "                                               title            date  \\\n",
       "0  Un equipo técnico–científico - Noticias de El ...  Date not found   \n",
       "1  Ancelotti se lleva a Arabia a cuatro canterano...  Date not found   \n",
       "2                                               None            None   \n",
       "\n",
       "                                                body  \n",
       "0  El periodismo que hacemos requiere tiempo, esf...  \n",
       "1  Ancelotti se lleva a Arabia a cuatro canterano...  \n",
       "2                                               None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def alert_folder_to_table(file_path):\n",
    "    \"\"\"Extracts text from all .eml files in a folder and returns a table filled with urls, article titles, and body text.\"\"\"\n",
    "    \n",
    "    urls = [url for url in urls_in_folder(file_path)]\n",
    "\n",
    "    return urls_to_table(urls)\n",
    "\n",
    "#demonstrates the function with the full mineria google alert folder\n",
    "\n",
    "#takes 12-18 minutes to run it may be helpful to comment out\n",
    "example_table = alert_folder_to_table('eml_files/1. El Salvador Mineria 1-94 eml')\n",
    "example_table[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e965c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports example_table to a csv file\n",
    "#example_table.to_csv('export_csv_files/example_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6519f028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fxguys lets users trade without checking identity',\n",
       " 'national asset built trust among',\n",
       " '1 listing price ozak ai',\n",
       " 'president nayib bukele made news',\n",
       " 'framework helps investors earn regularly',\n",
       " 'yield real financial gains rather',\n",
       " 'high growth potential besides bitcoin',\n",
       " 'one main trait distinguishing fxguys',\n",
       " 'fxguys users get immediate benefits',\n",
       " 'investors seek options beyond long',\n",
       " 'profits plus broker trading revenue',\n",
       " 'lets users earn rewards',\n",
       " 'fxguys gives traders direct chances',\n",
       " 'top prop trading companies',\n",
       " 'fxg tokens gives users',\n",
       " 'fxguys platform gives access',\n",
       " 'investors direct financial rewards',\n",
       " 'price rises like bitcoin',\n",
       " 'prop trading funding program',\n",
       " 'offers clear financial growth',\n",
       " 'rewards users actively',\n",
       " 'every trade made',\n",
       " 'fxguys gives traders',\n",
       " 'several trade terminals',\n",
       " 'international monetary fund',\n",
       " 'fxg token costs',\n",
       " 'el salvador sticks',\n",
       " 'direct money gain',\n",
       " 'demand plus liquidity',\n",
       " 'trade2earn method gives',\n",
       " 'el salvador ’',\n",
       " 'el salvador ’',\n",
       " 'investors see fxguys',\n",
       " 'term price guessing',\n",
       " 'stage 3 presale',\n",
       " 'one major problem',\n",
       " 'kyc trade setup',\n",
       " 'exchange withdrawal fees',\n",
       " 'bukele buys bitcoin',\n",
       " 'bukele adds bitcoin',\n",
       " 'term price plan',\n",
       " 'new trading platform',\n",
       " 'standard crypto investments',\n",
       " 'reduce inflation risk',\n",
       " 'need trade choice',\n",
       " 'merely holding coins',\n",
       " 'staking trading prizes',\n",
       " 'follow bitcoin ’',\n",
       " 'presale success signals',\n",
       " 'makes fxguys one',\n",
       " 'increasing government control',\n",
       " 'bitcoin holders wait',\n",
       " '4 million raised',\n",
       " 'price growth',\n",
       " 'requires users',\n",
       " 'fxg tokens',\n",
       " 'bukele ’',\n",
       " 'financial plan',\n",
       " 'presale price',\n",
       " 'direct funds',\n",
       " 'financial system',\n",
       " 'fxguys offers',\n",
       " 'long term',\n",
       " 'staking gains',\n",
       " 'price rise',\n",
       " 'higher gains',\n",
       " 'fxguys shows',\n",
       " 'fxguys shows',\n",
       " 'fxguys removes',\n",
       " 'fxguys emerges',\n",
       " 'fxguys creates',\n",
       " 'fxguys changes',\n",
       " '4 million',\n",
       " 'trading funds',\n",
       " 'trading capital',\n",
       " 'trading bonuses',\n",
       " 'quiet investors',\n",
       " 'investors worry',\n",
       " 'investors look',\n",
       " 'investors look',\n",
       " 'fxguys stands',\n",
       " 'get returns',\n",
       " 'new opportunity',\n",
       " 'kyc rules',\n",
       " 'government limits',\n",
       " 'fxguys also',\n",
       " 'digital money',\n",
       " 'traders keep',\n",
       " 'network fees',\n",
       " 'charge fees',\n",
       " 'active traders',\n",
       " 'bitcoin keeps',\n",
       " 'transaction delays',\n",
       " 'stays unstable',\n",
       " 'services mentioned',\n",
       " 'roi promised',\n",
       " 'reward system',\n",
       " 'opinions expressed',\n",
       " 'one chance',\n",
       " 'necessarily represent',\n",
       " 'markets change',\n",
       " 'keep value',\n",
       " 'hold funds',\n",
       " 'friendly environments',\n",
       " 'first system',\n",
       " 'firm support',\n",
       " 'facing limits',\n",
       " 'educational purposes',\n",
       " 'dismissing warnings',\n",
       " 'digital reserve',\n",
       " 'currently priced',\n",
       " 'cryptocurrency investment',\n",
       " 'crypto reporter',\n",
       " 'crypto reporter',\n",
       " 'crypto reporter',\n",
       " 'completely decentralized',\n",
       " 'central platforms',\n",
       " 'central exchanges',\n",
       " 'better investment',\n",
       " 'adoption trends',\n",
       " 'stands apart',\n",
       " 'market cycles',\n",
       " 'defi market',\n",
       " 'loss caused',\n",
       " 'leading projects',\n",
       " 'content provider',\n",
       " 'trade',\n",
       " 'trade',\n",
       " 'plus',\n",
       " 'options',\n",
       " 'fxguys',\n",
       " 'trading',\n",
       " 'depend solely',\n",
       " 'investors',\n",
       " 'investors',\n",
       " 'platform',\n",
       " 'long',\n",
       " 'get',\n",
       " 'one',\n",
       " 'one',\n",
       " 'clear',\n",
       " 'traders',\n",
       " 'traders',\n",
       " 'profits',\n",
       " 'profits',\n",
       " 'offers',\n",
       " 'bitcoin',\n",
       " 'bitcoin',\n",
       " 'bitcoin',\n",
       " 'bitcoin',\n",
       " 'bitcoin',\n",
       " 'bitcoin',\n",
       " 'bitcoin',\n",
       " 'bitcoin',\n",
       " 'success',\n",
       " 'staking',\n",
       " 'risk',\n",
       " 'raised',\n",
       " 'program',\n",
       " 'program',\n",
       " 'method',\n",
       " 'makes',\n",
       " 'holding',\n",
       " 'holders',\n",
       " 'crypto',\n",
       " 'control',\n",
       " 'choice',\n",
       " 'stands',\n",
       " 'market',\n",
       " 'solely',\n",
       " 'projects',\n",
       " 'content',\n",
       " 'chance',\n",
       " 'caused',\n",
       " 'also',\n",
       " 'depend',\n",
       " 'depend',\n",
       " 'xrp',\n",
       " 'worries',\n",
       " 'wish',\n",
       " 'way',\n",
       " 'views',\n",
       " 'usually',\n",
       " 'use',\n",
       " 'use',\n",
       " 'trustworthiness',\n",
       " 'trader',\n",
       " 'trader',\n",
       " 'take',\n",
       " 'suits',\n",
       " 'statements',\n",
       " 'state',\n",
       " 'starts',\n",
       " 'short',\n",
       " 'share',\n",
       " 'selling',\n",
       " 'sell',\n",
       " 'role',\n",
       " 'responsible',\n",
       " 'responsible',\n",
       " 'reserves',\n",
       " 'research',\n",
       " 'reliance',\n",
       " 'ready',\n",
       " 'quality',\n",
       " 'provided',\n",
       " 'popular',\n",
       " 'offering',\n",
       " 'next',\n",
       " 'much',\n",
       " 'mt5',\n",
       " 'merging',\n",
       " 'matter',\n",
       " 'materials',\n",
       " 'match',\n",
       " 'less',\n",
       " 'involvement',\n",
       " 'invest',\n",
       " 'indirectly',\n",
       " 'idea',\n",
       " 'hopes',\n",
       " 'grows',\n",
       " 'goods',\n",
       " 'expand',\n",
       " 'eth',\n",
       " 'economy',\n",
       " 'dxtrade',\n",
       " 'directly',\n",
       " 'depends',\n",
       " 'damage',\n",
       " 'cycle',\n",
       " 'ctrader',\n",
       " 'contrast',\n",
       " 'connection',\n",
       " 'comparison',\n",
       " 'choose',\n",
       " 'buying',\n",
       " 'buying',\n",
       " 'buy',\n",
       " 'btc',\n",
       " 'brave',\n",
       " 'assets',\n",
       " 'article',\n",
       " 'article',\n",
       " 'article',\n",
       " 'article',\n",
       " 'approach',\n",
       " 'alleged',\n",
       " 'accuracy',\n",
       " '500',\n",
       " '2000',\n",
       " '20',\n",
       " '10',\n",
       " '05',\n",
       " '05',\n",
       " '000',\n",
       " '0',\n",
       " '0',\n",
       " '0']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_keywords_from_text(text, language='english', ignore=[]):\n",
    "    \"\"\" \n",
    "    Extracts keywords from a given text, ignoring specified keywords.\n",
    "    Not working yet... so far just kind of spews nonsense for some reason\n",
    "    \"\"\"\n",
    "    rake = Rake(language=language)\n",
    "    rake.extract_keywords_from_text(text)\n",
    "    top_phrases = rake.get_ranked_phrases()\n",
    "    return top_phrases\n",
    "\n",
    "trial_url = urls_in_file('eml_files/Google Alert - _Bitcoin_ _El Salvador__1.eml')[4]\n",
    "trial_text = extract_website_details(trial_url)[2]\n",
    "trial_keywords = extract_keywords_from_text(trial_text)\n",
    "trial_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62ea29f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
